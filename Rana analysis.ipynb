{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "923c1675",
   "metadata": {},
   "outputs": [],
   "source": [
    "csvfile = \"dataV2_cohortV3.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac8d6d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.formula.api as smf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.graph_objs as go\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.miscmodels.ordinal_model import OrderedModel\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "14787896",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(csvfile)\n",
    "data_use = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0c36a001",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>UNIQUE_id</th>\n",
       "      <th>UNIQUE_num_records</th>\n",
       "      <th>ELIGIBLE_consent</th>\n",
       "      <th>COVID_prevention_distancing</th>\n",
       "      <th>COVID_prevention_masks</th>\n",
       "      <th>COVID_prevention_hand_washing</th>\n",
       "      <th>COVID_prevention_reduce_people</th>\n",
       "      <th>COVID_prevention_avoid_trips</th>\n",
       "      <th>COVID_prevention_household</th>\n",
       "      <th>...</th>\n",
       "      <th>PSYCH_zimet_multidimensional_social_support_scale_score</th>\n",
       "      <th>PSYCH_zimet_multidimensional_social_support_family_subscale_score</th>\n",
       "      <th>PSYCH_zimet_multidimensional_social_support_significant_other_subscale_score</th>\n",
       "      <th>PSYCH_zimet_multidimensional_social_support_friends_subscale_score</th>\n",
       "      <th>WELLNESS_subjective_happiness_scale_score</th>\n",
       "      <th>WELLNESS_phq_score</th>\n",
       "      <th>WELLNESS_phq_score_y_n</th>\n",
       "      <th>WELLNESS_gad_score</th>\n",
       "      <th>WELLNESS_gad_score_y_n</th>\n",
       "      <th>REMOVE_case</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>cscs_00021</td>\n",
       "      <td>3</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Very closely</td>\n",
       "      <td>Very closely</td>\n",
       "      <td>Very closely</td>\n",
       "      <td>Very closely</td>\n",
       "      <td>Very closely</td>\n",
       "      <td>Somewhat closely</td>\n",
       "      <td>...</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.75</td>\n",
       "      <td>7.00</td>\n",
       "      <td>5.25</td>\n",
       "      <td>5.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>No (0-2)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No (0-2)</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21</td>\n",
       "      <td>cscs_00021</td>\n",
       "      <td>3</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Somewhat closely</td>\n",
       "      <td>Somewhat closely</td>\n",
       "      <td>Somewhat closely</td>\n",
       "      <td>Somewhat closely</td>\n",
       "      <td>Not at all</td>\n",
       "      <td>Not at all</td>\n",
       "      <td>...</td>\n",
       "      <td>6.750000</td>\n",
       "      <td>6.50</td>\n",
       "      <td>7.00</td>\n",
       "      <td>6.75</td>\n",
       "      <td>5.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>No (0-2)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No (0-2)</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>71</td>\n",
       "      <td>cscs_00074</td>\n",
       "      <td>3</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Somewhat closely</td>\n",
       "      <td>Somewhat closely</td>\n",
       "      <td>Somewhat closely</td>\n",
       "      <td>Not at all</td>\n",
       "      <td>Somewhat closely</td>\n",
       "      <td>Not at all</td>\n",
       "      <td>...</td>\n",
       "      <td>6.333333</td>\n",
       "      <td>6.00</td>\n",
       "      <td>6.50</td>\n",
       "      <td>6.50</td>\n",
       "      <td>6.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No (0-2)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No (0-2)</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>77</td>\n",
       "      <td>cscs_00080</td>\n",
       "      <td>2</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Somewhat closely</td>\n",
       "      <td>Very closely</td>\n",
       "      <td>Very closely</td>\n",
       "      <td>Somewhat closely</td>\n",
       "      <td>Somewhat closely</td>\n",
       "      <td>Somewhat closely</td>\n",
       "      <td>...</td>\n",
       "      <td>4.916667</td>\n",
       "      <td>4.00</td>\n",
       "      <td>5.75</td>\n",
       "      <td>5.00</td>\n",
       "      <td>6.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No (0-2)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No (0-2)</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>78</td>\n",
       "      <td>cscs_00080</td>\n",
       "      <td>2</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Somewhat closely</td>\n",
       "      <td>Very closely</td>\n",
       "      <td>Very closely</td>\n",
       "      <td>Somewhat closely</td>\n",
       "      <td>Somewhat closely</td>\n",
       "      <td>Somewhat closely</td>\n",
       "      <td>...</td>\n",
       "      <td>5.333333</td>\n",
       "      <td>4.50</td>\n",
       "      <td>6.25</td>\n",
       "      <td>5.25</td>\n",
       "      <td>6.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No (0-2)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>No (0-2)</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>845</th>\n",
       "      <td>11379</td>\n",
       "      <td>cscs_11760</td>\n",
       "      <td>3</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Somewhat closely</td>\n",
       "      <td>Very closely</td>\n",
       "      <td>Very closely</td>\n",
       "      <td>Very closely</td>\n",
       "      <td>Very closely</td>\n",
       "      <td>Very closely</td>\n",
       "      <td>...</td>\n",
       "      <td>3.916667</td>\n",
       "      <td>1.75</td>\n",
       "      <td>5.25</td>\n",
       "      <td>4.75</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Yes (3-6)</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Yes (3-6)</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>846</th>\n",
       "      <td>11380</td>\n",
       "      <td>cscs_11760</td>\n",
       "      <td>3</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Somewhat closely</td>\n",
       "      <td>Very closely</td>\n",
       "      <td>Very closely</td>\n",
       "      <td>Somewhat closely</td>\n",
       "      <td>Somewhat closely</td>\n",
       "      <td>Very closely</td>\n",
       "      <td>...</td>\n",
       "      <td>4.583333</td>\n",
       "      <td>1.75</td>\n",
       "      <td>6.50</td>\n",
       "      <td>5.50</td>\n",
       "      <td>3.50</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Yes (3-6)</td>\n",
       "      <td>2.0</td>\n",
       "      <td>No (0-2)</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>847</th>\n",
       "      <td>11412</td>\n",
       "      <td>cscs_11795</td>\n",
       "      <td>3</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Somewhat closely</td>\n",
       "      <td>Very closely</td>\n",
       "      <td>Somewhat closely</td>\n",
       "      <td>Somewhat closely</td>\n",
       "      <td>Somewhat closely</td>\n",
       "      <td>Not at all</td>\n",
       "      <td>...</td>\n",
       "      <td>5.416667</td>\n",
       "      <td>5.75</td>\n",
       "      <td>6.50</td>\n",
       "      <td>4.00</td>\n",
       "      <td>4.75</td>\n",
       "      <td>1.0</td>\n",
       "      <td>No (0-2)</td>\n",
       "      <td>2.0</td>\n",
       "      <td>No (0-2)</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>848</th>\n",
       "      <td>11428</td>\n",
       "      <td>cscs_11812</td>\n",
       "      <td>3</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Somewhat closely</td>\n",
       "      <td>Somewhat closely</td>\n",
       "      <td>Very closely</td>\n",
       "      <td>Somewhat closely</td>\n",
       "      <td>Somewhat closely</td>\n",
       "      <td>Somewhat closely</td>\n",
       "      <td>...</td>\n",
       "      <td>4.833333</td>\n",
       "      <td>3.25</td>\n",
       "      <td>7.00</td>\n",
       "      <td>4.25</td>\n",
       "      <td>3.75</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Yes (3-6)</td>\n",
       "      <td>2.0</td>\n",
       "      <td>No (0-2)</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>849</th>\n",
       "      <td>11430</td>\n",
       "      <td>cscs_11812</td>\n",
       "      <td>3</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Very closely</td>\n",
       "      <td>Very closely</td>\n",
       "      <td>Very closely</td>\n",
       "      <td>Very closely</td>\n",
       "      <td>Very closely</td>\n",
       "      <td>Very closely</td>\n",
       "      <td>...</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>4.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>4.50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>No (0-2)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>No (0-2)</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>850 rows Ã— 167 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0   UNIQUE_id  UNIQUE_num_records ELIGIBLE_consent  \\\n",
       "0            19  cscs_00021                   3              Yes   \n",
       "1            21  cscs_00021                   3              Yes   \n",
       "2            71  cscs_00074                   3              Yes   \n",
       "3            77  cscs_00080                   2              Yes   \n",
       "4            78  cscs_00080                   2              Yes   \n",
       "..          ...         ...                 ...              ...   \n",
       "845       11379  cscs_11760                   3              Yes   \n",
       "846       11380  cscs_11760                   3              Yes   \n",
       "847       11412  cscs_11795                   3              Yes   \n",
       "848       11428  cscs_11812                   3              Yes   \n",
       "849       11430  cscs_11812                   3              Yes   \n",
       "\n",
       "    COVID_prevention_distancing COVID_prevention_masks  \\\n",
       "0                  Very closely           Very closely   \n",
       "1              Somewhat closely       Somewhat closely   \n",
       "2              Somewhat closely       Somewhat closely   \n",
       "3              Somewhat closely           Very closely   \n",
       "4              Somewhat closely           Very closely   \n",
       "..                          ...                    ...   \n",
       "845            Somewhat closely           Very closely   \n",
       "846            Somewhat closely           Very closely   \n",
       "847            Somewhat closely           Very closely   \n",
       "848            Somewhat closely       Somewhat closely   \n",
       "849                Very closely           Very closely   \n",
       "\n",
       "    COVID_prevention_hand_washing COVID_prevention_reduce_people  \\\n",
       "0                    Very closely                   Very closely   \n",
       "1                Somewhat closely               Somewhat closely   \n",
       "2                Somewhat closely                     Not at all   \n",
       "3                    Very closely               Somewhat closely   \n",
       "4                    Very closely               Somewhat closely   \n",
       "..                            ...                            ...   \n",
       "845                  Very closely                   Very closely   \n",
       "846                  Very closely               Somewhat closely   \n",
       "847              Somewhat closely               Somewhat closely   \n",
       "848                  Very closely               Somewhat closely   \n",
       "849                  Very closely                   Very closely   \n",
       "\n",
       "    COVID_prevention_avoid_trips COVID_prevention_household  ...  \\\n",
       "0                   Very closely           Somewhat closely  ...   \n",
       "1                     Not at all                 Not at all  ...   \n",
       "2               Somewhat closely                 Not at all  ...   \n",
       "3               Somewhat closely           Somewhat closely  ...   \n",
       "4               Somewhat closely           Somewhat closely  ...   \n",
       "..                           ...                        ...  ...   \n",
       "845                 Very closely               Very closely  ...   \n",
       "846             Somewhat closely               Very closely  ...   \n",
       "847             Somewhat closely                 Not at all  ...   \n",
       "848             Somewhat closely           Somewhat closely  ...   \n",
       "849                 Very closely               Very closely  ...   \n",
       "\n",
       "    PSYCH_zimet_multidimensional_social_support_scale_score  \\\n",
       "0                                             6.000000        \n",
       "1                                             6.750000        \n",
       "2                                             6.333333        \n",
       "3                                             4.916667        \n",
       "4                                             5.333333        \n",
       "..                                                 ...        \n",
       "845                                           3.916667        \n",
       "846                                           4.583333        \n",
       "847                                           5.416667        \n",
       "848                                           4.833333        \n",
       "849                                           4.333333        \n",
       "\n",
       "     PSYCH_zimet_multidimensional_social_support_family_subscale_score  \\\n",
       "0                                                 5.75                   \n",
       "1                                                 6.50                   \n",
       "2                                                 6.00                   \n",
       "3                                                 4.00                   \n",
       "4                                                 4.50                   \n",
       "..                                                 ...                   \n",
       "845                                               1.75                   \n",
       "846                                               1.75                   \n",
       "847                                               5.75                   \n",
       "848                                               3.25                   \n",
       "849                                               4.00                   \n",
       "\n",
       "    PSYCH_zimet_multidimensional_social_support_significant_other_subscale_score  \\\n",
       "0                                                 7.00                             \n",
       "1                                                 7.00                             \n",
       "2                                                 6.50                             \n",
       "3                                                 5.75                             \n",
       "4                                                 6.25                             \n",
       "..                                                 ...                             \n",
       "845                                               5.25                             \n",
       "846                                               6.50                             \n",
       "847                                               6.50                             \n",
       "848                                               7.00                             \n",
       "849                                               5.00                             \n",
       "\n",
       "    PSYCH_zimet_multidimensional_social_support_friends_subscale_score  \\\n",
       "0                                                 5.25                   \n",
       "1                                                 6.75                   \n",
       "2                                                 6.50                   \n",
       "3                                                 5.00                   \n",
       "4                                                 5.25                   \n",
       "..                                                 ...                   \n",
       "845                                               4.75                   \n",
       "846                                               5.50                   \n",
       "847                                               4.00                   \n",
       "848                                               4.25                   \n",
       "849                                               4.00                   \n",
       "\n",
       "    WELLNESS_subjective_happiness_scale_score WELLNESS_phq_score  \\\n",
       "0                                        5.00                1.0   \n",
       "1                                        5.25                1.0   \n",
       "2                                        6.00                0.0   \n",
       "3                                        6.00                0.0   \n",
       "4                                        6.00                0.0   \n",
       "..                                        ...                ...   \n",
       "845                                      3.00                3.0   \n",
       "846                                      3.50                3.0   \n",
       "847                                      4.75                1.0   \n",
       "848                                      3.75                3.0   \n",
       "849                                      4.50                1.0   \n",
       "\n",
       "    WELLNESS_phq_score_y_n WELLNESS_gad_score WELLNESS_gad_score_y_n  \\\n",
       "0                 No (0-2)                0.0               No (0-2)   \n",
       "1                 No (0-2)                0.0               No (0-2)   \n",
       "2                 No (0-2)                0.0               No (0-2)   \n",
       "3                 No (0-2)                0.0               No (0-2)   \n",
       "4                 No (0-2)                1.0               No (0-2)   \n",
       "..                     ...                ...                    ...   \n",
       "845              Yes (3-6)                4.0              Yes (3-6)   \n",
       "846              Yes (3-6)                2.0               No (0-2)   \n",
       "847               No (0-2)                2.0               No (0-2)   \n",
       "848              Yes (3-6)                2.0               No (0-2)   \n",
       "849               No (0-2)                1.0               No (0-2)   \n",
       "\n",
       "    REMOVE_case  \n",
       "0            No  \n",
       "1            No  \n",
       "2            No  \n",
       "3            No  \n",
       "4            No  \n",
       "..          ...  \n",
       "845          No  \n",
       "846          No  \n",
       "847          No  \n",
       "848          No  \n",
       "849          No  \n",
       "\n",
       "[850 rows x 167 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9153d7fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['CONNECTION_activities_video_chat_p3m']  # Independent variables\n",
    "y = df['LONELY_direct']  # Dependent variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "eae149f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                          Rarely (e.g. less than 1 day)\n",
       "1           Some or a little of the time (e.g. 1-2 days)\n",
       "2                        None of the time (e.g., 0 days)\n",
       "3           Some or a little of the time (e.g. 1-2 days)\n",
       "4                        None of the time (e.g., 0 days)\n",
       "                             ...                        \n",
       "845    Occasionally or a moderate amount of time (e.g...\n",
       "846         Some or a little of the time (e.g. 1-2 days)\n",
       "847                     All of the time (e.g. 5-7 days)]\n",
       "848    Occasionally or a moderate amount of time (e.g...\n",
       "849         Some or a little of the time (e.g. 1-2 days)\n",
       "Name: LONELY_direct, Length: 850, dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c05a8577",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LONELY_direct\n",
       "Rarely (e.g. less than 1 day)                                199\n",
       "Some or a little of the time (e.g. 1-2 days)                 185\n",
       "None of the time (e.g., 0 days)                              185\n",
       "Occasionally or a moderate amount of time (e.g. 3-4 days)    164\n",
       "All of the time (e.g. 5-7 days)]                              83\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d5685007",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_map_dict = {\n",
    "    'None of the time (e.g., 0 days)': 0,\n",
    "    'Rarely (e.g. less than 1 day)': 1,\n",
    "    'Some or a little of the time (e.g. 1-2 days)' : 1,\n",
    "    'Occasionally or a moderate amount of time (e.g. 3-4 days)': 1,\n",
    "    'All of the time (e.g. 5-7 days)]': 1\n",
    "}\n",
    "\n",
    "y = y.replace(y_map_dict.keys(), y_map_dict.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "924091f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      1.0\n",
       "1      1.0\n",
       "2      0.0\n",
       "3      1.0\n",
       "4      0.0\n",
       "      ... \n",
       "845    1.0\n",
       "846    1.0\n",
       "847    1.0\n",
       "848    1.0\n",
       "849    1.0\n",
       "Name: LONELY_direct, Length: 850, dtype: float64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0fc7ccd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LONELY_direct\n",
       "1.0    631\n",
       "0.0    185\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7d280b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(130)\n",
    "train, test = model_selection.train_test_split(data_use, train_size=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6b7493a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle missing values\n",
    "X.dropna()\n",
    "y.dropna()\n",
    "\n",
    "# Split the data into training and testing sets (80% training, 20% testing)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "833c6bc5",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'Not in the past three months'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m logreg \u001b[38;5;241m=\u001b[39m LogisticRegression()\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Fit the model on the training data\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[43mlogreg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/sklearn/base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1150\u001b[0m     )\n\u001b[1;32m   1151\u001b[0m ):\n\u001b[0;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1205\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1206\u001b[0m     _dtype \u001b[38;5;241m=\u001b[39m [np\u001b[38;5;241m.\u001b[39mfloat64, np\u001b[38;5;241m.\u001b[39mfloat32]\n\u001b[0;32m-> 1208\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1209\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1210\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1211\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1212\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1213\u001b[0m \u001b[43m    \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mC\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1214\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msolver\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mliblinear\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msag\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msaga\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1215\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1216\u001b[0m check_classification_targets(y)\n\u001b[1;32m   1217\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(y)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/sklearn/base.py:622\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    620\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[1;32m    621\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 622\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_X_y\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    623\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[1;32m    625\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1146\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1141\u001b[0m         estimator_name \u001b[38;5;241m=\u001b[39m _check_estimator_name(estimator)\n\u001b[1;32m   1142\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1143\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires y to be passed, but the target y is None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1144\u001b[0m     )\n\u001b[0;32m-> 1146\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1147\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1148\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1149\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_large_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1150\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1151\u001b[0m \u001b[43m    \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1152\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1153\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1154\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_2d\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1155\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_nd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1156\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1157\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1158\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1159\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1160\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1162\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric, estimator\u001b[38;5;241m=\u001b[39mestimator)\n\u001b[1;32m   1164\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:915\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    913\u001b[0m         array \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mastype(array, dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    914\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 915\u001b[0m         array \u001b[38;5;241m=\u001b[39m \u001b[43m_asarray_with_order\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    916\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ComplexWarning \u001b[38;5;28;01mas\u001b[39;00m complex_warning:\n\u001b[1;32m    917\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    918\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComplex data not supported\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(array)\n\u001b[1;32m    919\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcomplex_warning\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/sklearn/utils/_array_api.py:380\u001b[0m, in \u001b[0;36m_asarray_with_order\u001b[0;34m(array, dtype, order, copy, xp)\u001b[0m\n\u001b[1;32m    378\u001b[0m     array \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39marray(array, order\u001b[38;5;241m=\u001b[39morder, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m    379\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 380\u001b[0m     array \u001b[38;5;241m=\u001b[39m \u001b[43mnumpy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    382\u001b[0m \u001b[38;5;66;03m# At this point array is a NumPy ndarray. We convert it to an array\u001b[39;00m\n\u001b[1;32m    383\u001b[0m \u001b[38;5;66;03m# container that is consistent with the input's namespace.\u001b[39;00m\n\u001b[1;32m    384\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m xp\u001b[38;5;241m.\u001b[39masarray(array)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/series.py:953\u001b[0m, in \u001b[0;36mSeries.__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m    906\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    907\u001b[0m \u001b[38;5;124;03mReturn the values as a NumPy array.\u001b[39;00m\n\u001b[1;32m    908\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    950\u001b[0m \u001b[38;5;124;03m      dtype='datetime64[ns]')\u001b[39;00m\n\u001b[1;32m    951\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    952\u001b[0m values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values\n\u001b[0;32m--> 953\u001b[0m arr \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    954\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m using_copy_on_write() \u001b[38;5;129;01mand\u001b[39;00m astype_is_view(values\u001b[38;5;241m.\u001b[39mdtype, arr\u001b[38;5;241m.\u001b[39mdtype):\n\u001b[1;32m    955\u001b[0m     arr \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mview()\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'Not in the past three months'"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Initialize the model\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "# Fit the model on the training data\n",
    "logreg.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "024396db",
   "metadata": {},
   "source": [
    "--- \n",
    "# last edit here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5f02d007",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'Not in the past three months'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m model \u001b[38;5;241m=\u001b[39m LinearRegression()\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Fit the model on the training data\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Make predictions on the test set\u001b[39;00m\n\u001b[1;32m      8\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/sklearn/base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1150\u001b[0m     )\n\u001b[1;32m   1151\u001b[0m ):\n\u001b[0;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_base.py:678\u001b[0m, in \u001b[0;36mLinearRegression.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    674\u001b[0m n_jobs_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs\n\u001b[1;32m    676\u001b[0m accept_sparse \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpositive \u001b[38;5;28;01melse\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsc\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcoo\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m--> 678\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    679\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_numeric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmulti_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m    680\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    682\u001b[0m has_sw \u001b[38;5;241m=\u001b[39m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    683\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_sw:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/sklearn/base.py:622\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    620\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[1;32m    621\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 622\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_X_y\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    623\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[1;32m    625\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1146\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1141\u001b[0m         estimator_name \u001b[38;5;241m=\u001b[39m _check_estimator_name(estimator)\n\u001b[1;32m   1142\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1143\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires y to be passed, but the target y is None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1144\u001b[0m     )\n\u001b[0;32m-> 1146\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1147\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1148\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1149\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_large_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1150\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1151\u001b[0m \u001b[43m    \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1152\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1153\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1154\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_2d\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1155\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_nd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1156\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1157\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1158\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1159\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1160\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1162\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric, estimator\u001b[38;5;241m=\u001b[39mestimator)\n\u001b[1;32m   1164\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:915\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    913\u001b[0m         array \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mastype(array, dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    914\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 915\u001b[0m         array \u001b[38;5;241m=\u001b[39m \u001b[43m_asarray_with_order\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    916\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ComplexWarning \u001b[38;5;28;01mas\u001b[39;00m complex_warning:\n\u001b[1;32m    917\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    918\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComplex data not supported\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(array)\n\u001b[1;32m    919\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcomplex_warning\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/sklearn/utils/_array_api.py:380\u001b[0m, in \u001b[0;36m_asarray_with_order\u001b[0;34m(array, dtype, order, copy, xp)\u001b[0m\n\u001b[1;32m    378\u001b[0m     array \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39marray(array, order\u001b[38;5;241m=\u001b[39morder, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m    379\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 380\u001b[0m     array \u001b[38;5;241m=\u001b[39m \u001b[43mnumpy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    382\u001b[0m \u001b[38;5;66;03m# At this point array is a NumPy ndarray. We convert it to an array\u001b[39;00m\n\u001b[1;32m    383\u001b[0m \u001b[38;5;66;03m# container that is consistent with the input's namespace.\u001b[39;00m\n\u001b[1;32m    384\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m xp\u001b[38;5;241m.\u001b[39masarray(array)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/series.py:953\u001b[0m, in \u001b[0;36mSeries.__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m    906\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    907\u001b[0m \u001b[38;5;124;03mReturn the values as a NumPy array.\u001b[39;00m\n\u001b[1;32m    908\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    950\u001b[0m \u001b[38;5;124;03m      dtype='datetime64[ns]')\u001b[39;00m\n\u001b[1;32m    951\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    952\u001b[0m values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values\n\u001b[0;32m--> 953\u001b[0m arr \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    954\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m using_copy_on_write() \u001b[38;5;129;01mand\u001b[39;00m astype_is_view(values\u001b[38;5;241m.\u001b[39mdtype, arr\u001b[38;5;241m.\u001b[39mdtype):\n\u001b[1;32m    955\u001b[0m     arr \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mview()\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'Not in the past three months'"
     ]
    }
   ],
   "source": [
    "# Initialize the Linear Regression model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Fit the model on the training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model's performance using Mean Squared Error (MSE) and R-squared\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "print(f\"R-squared: {r2}\")\n",
    "\n",
    "# Hypothesis Test for Regression Coefficients\n",
    "# Null hypothesis (H0): The coefficient is equal to 0 (no effect)\n",
    "# Alternative hypothesis (H1): The coefficient is not equal to 0 (significant effect)\n",
    "\n",
    "# Get the coefficients and intercept\n",
    "coefficients = model.coef_\n",
    "intercept = model.intercept_\n",
    "\n",
    "# Perform t-tests for the regression coefficients\n",
    "X_train_with_intercept = np.c_[np.ones(X_train.shape[0]), X_train]  # Add intercept for testing\n",
    "X_train_with_intercept = np.array(X_train_with_intercept)\n",
    "\n",
    "# Compute the standard errors of the coefficients\n",
    "predictions = model.predict(X_train)\n",
    "residuals = y_train - predictions\n",
    "sse = np.sum(residuals**2)\n",
    "var_beta = np.linalg.inv(np.dot(X_train_with_intercept.T, X_train_with_intercept)) * sse / (X_train.shape[0] - X_train.shape[1])\n",
    "\n",
    "# Standard errors of the coefficients\n",
    "std_errors = np.sqrt(np.diag(var_beta))\n",
    "\n",
    "# t-statistics for each coefficient\n",
    "t_stats = coefficients / std_errors\n",
    "\n",
    "# Degrees of freedom: number of observations - number of coefficients\n",
    "df = X_train.shape[0] - X_train.shape[1]\n",
    "\n",
    "# p-values from the t-distribution\n",
    "p_values = [2 * (1 - stats.t.cdf(np.abs(t_stat), df)) for t_stat in t_stats]\n",
    "\n",
    "# Print the coefficients and their p-values\n",
    "for i, (coef, p_val) in enumerate(zip(coefficients, p_values)):\n",
    "    print(f\"Coefficient {i}: {coef}, p-value: {p_val}\")\n",
    "\n",
    "# If p-value < 0.05, reject the null hypothesis (significant predictor)\n",
    "significant_predictors = [i for i, p in enumerate(p_values) if p < 0.05]\n",
    "print(f\"Significant predictors: {significant_predictors}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aeb451a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8cc94a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows with missing values in either X or y\n",
    "data = pd.concat([X, y], axis=1)  # Combine features and target for easy removal of rows with NaNs\n",
    "data_cleaned = data.dropna()  # Drop rows where any NaN value is present\n",
    "\n",
    "# Separate the features and target variable again\n",
    "X_cleaned = data_cleaned.drop(columns=[y.name])  # Drop the target column to keep only features\n",
    "y_cleaned = data_cleaned[y.name]  # Keep the target column\n",
    "\n",
    "# Now X_cleaned and y_cleaned have no missing values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb37eb8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Check if mode() returns a valid value\n",
    "mode_value = y.mode()\n",
    "if not mode_value.empty:\n",
    "    y_cleaned = y.fillna(mode_value[0])  # Fill with the most frequent value\n",
    "else:\n",
    "    # If no mode is found, use a fallback value (e.g., the median)\n",
    "    y_cleaned = y.fillna(y.median())  # Alternatively, you can use mean() or any other strategy\n",
    "\n",
    "# Fill missing values with the mean for features\n",
    "X_cleaned = X.fillna(X.mean())\n",
    "\n",
    "# Fill missing values in the target variable with the mode (most frequent value)\n",
    "y_cleaned = y.fillna(y.mode()[0])\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_cleaned, y_cleaned, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79fd69ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.isna().sum())  # Count NaNs in each column\n",
    "print(X)  # Inspect the data for unexpected values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f2560a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.dropna()\n",
    "y = y[X.index]  # Keep corresponding rows in y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985d6af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['CONNECTION_activities_video_chat_p3m'].unique())\n",
    "print(df['video_chat_encoded'].unique())  # Ensure the mapping is correct\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c51b7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6a9c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(df['text_message_encoded'].unique())  # Ensure the mapping is correct\n",
    "print(df['CONNECTION_activities_text_or_messaged_p3m'].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f26025",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df), len(df['text_message_encoded']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb491932",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text_message_encoded'] = df['CONNECTION_activities_text_or_messaged_p3m'].map(activity_mapping).fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d43a5bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "lonely_mapping = {\n",
    "    'Rarely': 0,\n",
    "    'Some or a little of the time': 1,\n",
    "    'None of the time': 2,\n",
    "    'Occasionally or a moderate amount of time': 3,\n",
    "    'All of the time': 4\n",
    "}\n",
    "df['LONELY_direct_encoded'] = df['LONELY_direct'].map(lonely_mapping)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f94d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows with missing values from the original X_train and y_train first\n",
    "valid_rows = ~np.isnan(X_train).any(axis=1)  # Mask for rows with no NaNs in X_train\n",
    "X_train_clean = X_train[valid_rows]\n",
    "y_train_clean = y_train[valid_rows]  # Apply the same mask to y_train\n",
    "\n",
    "# Now standardize the features after cleaning\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_clean)\n",
    "\n",
    "# Fit the model again with the cleaned and scaled data\n",
    "log_reg.fit(X_train_scaled, y_train_clean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40c9d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 2: Standardize the independent variables (optional but recommended)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Step 3: Fit the multinomial logistic regression model\n",
    "log_reg = LogisticRegression(multi_class='multinomial', solver='lbfgs', max_iter=500)\n",
    "log_reg.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Step 4: Print the model coefficients\n",
    "print(\"Model coefficients:\", log_reg.coef_)\n",
    "print(\"Intercept:\", log_reg.intercept_)\n",
    "\n",
    "# Step 5: Make predictions and evaluate the model\n",
    "y_pred = log_reg.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the model's performance\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "815b153f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed82195",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5835ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Encode independent variables (ordinal or dummy)\n",
    "df['video_chat_encoded'] = df['CONNECTION_activities_video_chat_p3m'].map({\n",
    "    'Less than monthly': 1,\n",
    "    'Monthly': 2,\n",
    "    'Weekly': 3,\n",
    "    'A few times a week': 4,\n",
    "    'Daily or almost daily': 5\n",
    "})\n",
    "df['text_message_encoded'] = df['CONNECTION_activities_text_or_messaged_p3m'].map({\n",
    "    'Less than monthly': 1,\n",
    "    'Monthly': 2,\n",
    "    'Weekly': 3,\n",
    "    'A few times a week': 4,\n",
    "    'Daily or almost daily': 5\n",
    "})\n",
    "\n",
    "# Step 2: Encode dependent variable (ordinal)\n",
    "df['LONELY_direct_encoded'] = df['LONELY_direct'].map({\n",
    "    'None of the time': 0,\n",
    "    'Rarely': 1,\n",
    "    'Some or a little of the time': 2,\n",
    "    'Occasionally or a moderate amount of time': 3,\n",
    "    'All of the time': 4\n",
    "})\n",
    "\n",
    "# Step 3: Define independent and dependent variables\n",
    "X = df[['video_chat_encoded', 'text_message_encoded']]\n",
    "X = sm.add_constant(X)  # Add a constant term for the intercept\n",
    "y = df['LONELY_direct_encoded']\n",
    "\n",
    "# Step 4: Fit ordinal logistic regression\n",
    "model = OrderedModel(y, X, distr='logit')  # Using logistic distribution\n",
    "result = model.fit()\n",
    "\n",
    "# Step 5: Summarize results\n",
    "print(result.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e05bfea9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc9d2b0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5877fc33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b347edaa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2917b683",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281e912d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0776c74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fbcfc9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5836fe59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b6d541",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "cols = pd.read_csv('var_names.csv')\n",
    "data = pd.read_csv('CSCS_data_anon.csv',\n",
    "                   na_values=[\"9999\", \"\", \" \", \"Presented but no response\", \"NA\"])\n",
    "empty = (data.isna().sum()==data.shape[0])\n",
    "data = data[empty.index[~empty]] # keep non empty columns only\n",
    "\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a1953d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This variable indicates cases we recommend removing from an analysis due to fast completion times or possible fraudulent responses.\n",
    "data.REMOVE_case.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f54113",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's just keep the recommended data\n",
    "dataV2 = data[data.REMOVE_case=='No'].copy()\n",
    "dataV2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c358b580",
   "metadata": {},
   "outputs": [],
   "source": [
    "# And select out participants who are part of the cohort data \n",
    "# (but may also be a part of the cross-sectional data)\n",
    "dataV2_cohort = dataV2[dataV2.SURVEY_cohort_participant].copy()\n",
    "dataV2_cohort.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668d1732",
   "metadata": {},
   "outputs": [],
   "source": [
    "# And remove year 2023 for which there's not yet much data collected\n",
    "dataV2_cohortV2 = dataV2_cohort[dataV2_cohort.SURVEY_collection_year!=2023].copy()\n",
    "dataV2_cohortV2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d89018",
   "metadata": {},
   "outputs": [],
   "source": [
    "# And remove columns that have less than some number of missing values\n",
    "# We could consider no missing values using 850, or...?\n",
    "missingness_limit = 100 # this retains 166 of 1024 columns that aren't fully empty\n",
    "columns2keep = dataV2_cohortV2.isna().sum() < missingness_limit\n",
    "columns2keep = columns2keep.index[columns2keep]\n",
    "dataV2_cohortV3 = dataV2_cohortV2[columns2keep].copy()\n",
    "dataV2_cohortV3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a51f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_of_interest = [\n",
    "    'LIFESTYLE_time_use_balance_media',\n",
    "    'CONNECTION_social_time_friends_p7d',\n",
    "    'WELLNESS_malach_pines_burnout_measure_depressed'\n",
    "]\n",
    "data_filtered = dataV2_cohortV2[columns_of_interest].copy()\n",
    "\n",
    "# Drop rows with missing values in relevant columns\n",
    "data_filtered = data_filtered.dropna(subset=columns_of_interest)\n",
    "\n",
    "data_filtered['LIFESTYLE_time_use_balance_media'] = data_filtered['LIFESTYLE_time_use_balance_media'].map({\n",
    "    'Too little': 1,\n",
    "    'Just the right amount': 2,\n",
    "    'Too much': 3\n",
    "})\n",
    "\n",
    "print(data_filtered.head())\n",
    "\n",
    "X = data_filtered[['LIFESTYLE_time_use_balance_media', 'CONNECTION_social_time_friends_p7d']]\n",
    "y = data_filtered['WELLNESS_malach_pines_burnout_measure_depressed']\n",
    "\n",
    "import statsmodels.api as sm\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "y = pd.to_numeric(y, errors='coerce')  # Convert y to numeric, coercing errors to NaN\n",
    "X = X.apply(pd.to_numeric, errors='coerce')  # Convert X to numeric, coercing errors to NaN\n",
    "\n",
    "y = y.dropna()  # Drop rows with NaN in y\n",
    "X = X.dropna()  # Drop rows with NaN in X\n",
    "\n",
    "model = sm.OLS(y, X).fit()\n",
    "print(model.summary())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
